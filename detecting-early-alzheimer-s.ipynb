{"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"default_view":{},"name":"FinalReport_Code.ipynb","provenance":[],"version":"0.3.2","views":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3398,"sourceType":"datasetVersion","datasetId":1980}],"dockerImageVersionId":46,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DETECTING EARLY ALZHEIMER'S USING MRI DATA AND MACHINE LEARNING\n----\n## TABLE OF CONTENT\n1. Problem Statement\n2. Data\n  1. Dataset Description\n  2. Column Descriptors\n3. Related Work\n4. Exploratory Data Analysis\n5. Data Precrocessing\n  1. Removing rows with missing values\n  2. Imputation\n  3. Splitting Train/Validation/Test Sets\n  4. Cross-validation\n6. Model\n  1. Performance Measure\n  2. Logistic Regression\n  3. Support Vector Machine\n  4. Decision Tree\n  5. Random Forest Classifier\n  6. AdaBoost\n7. Results\n\n## TEAM MEMBERS\n1. Hriday Ranka\n2. Raghav Agarwal\n3. Anvay Tere\n","metadata":{"id":"RPIBkis9u_2Q","_uuid":"31aff975d245f351c6a47a411251c09cf0df142a"}},{"cell_type":"markdown","source":"# 1. PROBLEM STATEMENT\n---\n## ALZHEIMER'S DISEASE\n\n* [Alzheimer's disease (AD)](https://en.wikipedia.org/wiki/Alzheimer%27s_disease) is a neurodegenerative disorder of uncertain cause and pathogenesis that primarily affects older adults and is the most common cause of dementia.\n* The earliest clinical manifestation of AD is selective memory impairment and while treatments are available to ameliorate some symptoms, there is no cure currently available.\n* Brain Imaging via magnetic resonance imaging (MRI), is used for evaluation of patients with suspected AD.\n* MRI findings include both, local and generalized shrinkage of brain tissue. Below is a pictorial representation of tissue shrinkage: ![braintissue](./Alzheimer's_disease_brain_comparison.jpg)\n* Some studies have suggested that MRI features may predict rate of decline of AD and may guide therapy in the future.\n* However in order to reach that stage clinicians and researchers will have to make use of machine learning techniques that can accurately predict progress of a patient from mild cognitive impairment to dementia.\n* We propose to develop a sound model that can help clinicians do that and predict early alzheimer's.","metadata":{"id":"Rqz5sHwoScR7","_uuid":"fedeb7d2f5ade1370c0422693aedff04d4d886f8"}},{"cell_type":"markdown","source":"# 2. DATA\n---\nThe team has found MRI related data that was generated by the Open Access Series of Imaging Studies (OASIS) project that is available both, on their [website](www.oasis-brains.org) and [kaggle](www.kaggle.com/jboysen/mri-and-alzheimers) that can be utilized for the purpose of training various machine learning models to identify patients with mild to moderate dementia.\n\n## 2.A DATASET DESCRIPTION\n* We will be using the [longitudinal MRI data](http://www.oasis-brains.org/pdf/oasis_longitudinal.csv).\n* The dataset consists of a longitudinal MRI data of 150 subjects aged 60 to 96.\n* Each subject was scanned at least once.\n* Everyone is right-handed.\n* 72 of the subjects were grouped as 'Nondemented' throughout the study.\n* 64 of the subjects were grouped as 'Demented' at the time of their initial visits and remained so throughout the study.\n* 14 subjects were grouped as 'Nondemented' at the time of their initial visit and were subsequently characterized as 'Demented' at a later visit. These fall under the 'Converted' category.\n\n## 2.B COLUMN DESCRIPTORS  \n\n|COL  |FULL-FORMS                          |\n|-----|------------------------------------|\n|EDUC |Years of education                  |\n|SES  |Socioeconomic Status                |\n|MMSE |[Mini Mental State Examination](http://www.dementiatoday.com/wp-content/uploads/2012/06/MiniMentalStateExamination.pdf)       |\n|CDR  |[Clinical Dementia Rating](http://knightadrc.wustl.edu/cdr/PDFs/CDR_Table.pdf)            |\n|eTIV |[Estimated Total Intracranial Volume](https://link.springer.com/article/10.1007/s12021-015-9266-5) |\n|nWBV |[Normalize Whole Brain Volume](https://www.ncbi.nlm.nih.gov/pubmed/11547042)        |\n|ASF  |[Atlas Scaling Factor](http://www.sciencedirect.com/science/article/pii/S1053811904003271)                |\n","metadata":{"id":"FG0zBhPkScR7","_uuid":"6fe31a2ec5929f28eff868ae06f907daeb26fb5c"}},{"cell_type":"markdown","source":"# 4. EXPLORATORY DATA ANALYSIS (EDA)\n---\n\nIn this section, we have focused on exploring the relationship between each feature of MRI tests and dementia of the patient. The reason we conducted this Exploratory Data Analysis process is to state the relationship of data explicitly through a graph so that we could assume the correlations before data extraction or data analysis. It might help us to understand the nature of the data and to select the appropriate analysis method for the model later.\n\nThe minimum, maximum, and average values of each feature for graph implementation are as follows.\n\n||Min|Max|Mean|\n|---\n|Educ|6|23|14.6|\n|SES|1|5|2.34\n|MMSE|17|30|27.2|\n|CDR|0|1|0.29|\n|eTIV|1123|1989|1490|\n|nWBV|0.66|0.837|0.73|\n|ASF|0.883|1.563|1.2|","metadata":{"id":"XZY2wtKYtH3h","_uuid":"566105ab7a54c9420a4f649dea3fa1f52da1d79d"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nsns.set()\n\ndf = pd.read_csv('../input/oasis_longitudinal.csv')\ndf.head()","metadata":{"_uuid":"6a720755860b07d7eb93e458306ec1b6fa079ed5","execution":{"iopub.status.busy":"2024-04-29T14:23:06.446227Z","iopub.execute_input":"2024-04-29T14:23:06.446603Z","iopub.status.idle":"2024-04-29T14:23:06.496860Z","shell.execute_reply.started":"2024-04-29T14:23:06.446559Z","shell.execute_reply":"2024-04-29T14:23:06.495724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.loc[df['Visit']==1] # use first visit data only because of the analysis we're doing\ndf = df.reset_index(drop=True) # reset index after filtering first visit data\ndf['M/F'] = df['M/F'].replace(['F','M'], [0,1]) # M/F column\ndf['Group'] = df['Group'].replace(['Converted'], ['Demented']) # Target variable\ndf['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\ndf = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns","metadata":{"_uuid":"08991ab4c6c3aef89ad366662aad97a846aa9d8f","execution":{"iopub.status.busy":"2024-04-29T14:23:06.498261Z","iopub.execute_input":"2024-04-29T14:23:06.498694Z","iopub.status.idle":"2024-04-29T14:23:06.523557Z","shell.execute_reply.started":"2024-04-29T14:23:06.498628Z","shell.execute_reply":"2024-04-29T14:23:06.522121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bar drawing function\ndef bar_chart(feature):\n    Demented = df[df['Group']==1][feature].value_counts()\n    Nondemented = df[df['Group']==0][feature].value_counts()\n    df_bar = pd.DataFrame([Demented,Nondemented])\n    df_bar.index = ['Demented','Nondemented']\n    df_bar.plot(kind='bar',stacked=True, figsize=(8,5))","metadata":{"executionInfo":{"elapsed":11761,"status":"error","timestamp":1512599691671,"user":{"displayName":"Saurin Parikh","photoUrl":"//lh3.googleusercontent.com/-6RG-0wrBKjU/AAAAAAAAAAI/AAAAAAAABpU/h5Zwf5zd3tk/s50-c-k-no/photo.jpg","userId":"104703813675171986785"},"user_tz":300},"id":"-4-ZVrHJslSF","outputId":"5f5cc170-02d6-41d4-f5f2-3b575833b56b","_uuid":"9175b97a0b02ff8ace2e3bc8a6327488b3232783","execution":{"iopub.status.busy":"2024-04-29T14:23:06.525455Z","iopub.execute_input":"2024-04-29T14:23:06.525772Z","iopub.status.idle":"2024-04-29T14:23:06.542340Z","shell.execute_reply.started":"2024-04-29T14:23:06.525721Z","shell.execute_reply":"2024-04-29T14:23:06.541162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Gender  and  Group ( Femal=0, Male=1)\nbar_chart('M/F')\nplt.xlabel('Group')\nplt.ylabel('Number of patients')\nplt.legend()\nplt.title('Gender and Demented rate')","metadata":{"id":"k-92eJ7pslSL","outputId":"d9940867-44f6-4d3a-f6fb-ddef5630877e","_uuid":"5f8599d4f70b78047011217e3bbcaa26311fddc6","execution":{"iopub.status.busy":"2024-04-29T14:23:06.544153Z","iopub.execute_input":"2024-04-29T14:23:06.544537Z","iopub.status.idle":"2024-04-29T14:23:06.765303Z","shell.execute_reply.started":"2024-04-29T14:23:06.544477Z","shell.execute_reply":"2024-04-29T14:23:06.764140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above graph indicates that men are more likely with dementia than women.","metadata":{"id":"9m16iCGyslSO","_uuid":"46c3ccb6893e52a6636e9a764539a92084f90407"}},{"cell_type":"code","source":"#MMSE : Mini Mental State Examination\n# Nondemented = 0, Demented =1\n# Nondemented has higher test result ranging from 25 to 30. \n#Min 17 ,MAX 30\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'MMSE',shade= True)\nfacet.set(xlim=(0, df['MMSE'].max()))\nfacet.add_legend()\nplt.xlim(15.30)","metadata":{"id":"QfZMuTl7slSP","outputId":"b3a6a8a7-5cd6-48eb-e631-20b8d30c3bad","_uuid":"e1b8fbe86bbf469971aed915c2b8e9caa9cdbe53","execution":{"iopub.status.busy":"2024-04-29T14:23:06.767298Z","iopub.execute_input":"2024-04-29T14:23:06.767855Z","iopub.status.idle":"2024-04-29T14:23:07.066093Z","shell.execute_reply.started":"2024-04-29T14:23:06.767768Z","shell.execute_reply":"2024-04-29T14:23:07.064672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The chart shows Nondemented group got much more higher MMSE scores than Demented group.","metadata":{"id":"WumyA7d6slSR","_uuid":"8d01f7c6b66442f0b1eeb814464cec8654a24945"}},{"cell_type":"code","source":"#bar_chart('ASF') = Atlas Scaling Factor\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'ASF',shade= True)\nfacet.set(xlim=(0, df['ASF'].max()))\nfacet.add_legend()\nplt.xlim(0.5, 2)\n\n#eTIV = Estimated Total Intracranial Volume\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'eTIV',shade= True)\nfacet.set(xlim=(0, df['eTIV'].max()))\nfacet.add_legend()\nplt.xlim(900, 2100)\n\n#'nWBV' = Normalized Whole Brain Volume\n# Nondemented = 0, Demented =1\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'nWBV',shade= True)\nfacet.set(xlim=(0, df['nWBV'].max()))\nfacet.add_legend()\nplt.xlim(0.6,0.9)","metadata":{"id":"JPuWkiWGslSS","outputId":"4088e3c2-8493-41d2-c61a-c386e784fd37","_uuid":"4dc483b489417595af5d23cf7a44de13c8ba371d","execution":{"iopub.status.busy":"2024-04-29T14:23:07.067988Z","iopub.execute_input":"2024-04-29T14:23:07.068402Z","iopub.status.idle":"2024-04-29T14:23:08.003333Z","shell.execute_reply.started":"2024-04-29T14:23:07.068328Z","shell.execute_reply":"2024-04-29T14:23:08.002229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The chart indicates that Nondemented group has higher brain volume ratio than Demented group. This is assumed to be because the diseases affect the brain to be shrinking its tissue. ","metadata":{"id":"1LC-PdJislSV","_uuid":"96f2d269e35927b57c5068b2b3dda2d145ae91f4"}},{"cell_type":"code","source":"#AGE. Nondemented =0, Demented =0\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, df['Age'].max()))\nfacet.add_legend()\nplt.xlim(50,100)","metadata":{"id":"w6rN7jjSslSW","outputId":"fbb23e63-a926-477c-c6ff-fc87933c1ea6","_uuid":"87a846e38f21e28b3c7ad6bae536b7cd2c3e2466","execution":{"iopub.status.busy":"2024-04-29T14:23:08.005027Z","iopub.execute_input":"2024-04-29T14:23:08.005327Z","iopub.status.idle":"2024-04-29T14:23:08.282946Z","shell.execute_reply.started":"2024-04-29T14:23:08.005276Z","shell.execute_reply":"2024-04-29T14:23:08.282082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a higher concentration of 70-80 years old in the Demented patient group than those in the nondemented patients.\nWe guess patients who suffered from that kind of disease has lower survival rate so that there are a few of 90 years old.","metadata":{"id":"VlQHpQRWslSY","_uuid":"e491fe3ded880c040a17cde07279b0474b00ff7a"}},{"cell_type":"code","source":"#'EDUC' = Years of Education\n# Nondemented = 0, Demented =1\nfacet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\nfacet.map(sns.kdeplot,'EDUC',shade= True)\nfacet.set(xlim=(df['EDUC'].min(), df['EDUC'].max()))\nfacet.add_legend()\nplt.ylim(0, 0.16)","metadata":{"id":"w6rN7jjSslSW","outputId":"fbb23e63-a926-477c-c6ff-fc87933c1ea6","_uuid":"8177a32eff0fece26f2220ccc046843347afc41e","execution":{"iopub.status.busy":"2024-04-29T14:23:08.284421Z","iopub.execute_input":"2024-04-29T14:23:08.284757Z","iopub.status.idle":"2024-04-29T14:23:08.602949Z","shell.execute_reply.started":"2024-04-29T14:23:08.284694Z","shell.execute_reply":"2024-04-29T14:23:08.601672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Intermediate Result Summary\n1. Men are more likely with demented, an Alzheimer's Disease, than Women.\n2. Demented patients were less educated in terms of years of education.\n3. Nondemented group has higher brain volume than Demented group.\n4. Higher concentration of 70-80 years old in Demented group than those in the nondemented patients.","metadata":{"id":"HGKJOeWYslSZ","_uuid":"26e6c99d943c7e371e9fd7c3b962449996e743fd"}},{"cell_type":"markdown","source":"# 5. Data Preprocessing\n---\nWe identified 8 rows with missing values in SES column. We deal with this issue with 2 approaches. One is just to drop the rows with missing values. The other is to replace the missing values with the corresponing values, also known as 'Imputation'. Since we have only 150 data, I assume imputation would help the performance of our model.","metadata":{"id":"dR7e2FEuScR8","_uuid":"80a9f0ebb50abd31cfa14ed7d93204d00f313543"}},{"cell_type":"code","source":"# Check missing values by each column\npd.isnull(df).sum() \n# The column, SES has 8 missing values","metadata":{"id":"crn5DxTUScSI","outputId":"10613858-0403-4c42-aea7-7bc3635ef60e","_uuid":"c485e9bdba313a2897fa58aa61406f07c2206c27","execution":{"iopub.status.busy":"2024-04-29T14:23:08.604687Z","iopub.execute_input":"2024-04-29T14:23:08.605252Z","iopub.status.idle":"2024-04-29T14:23:08.617873Z","shell.execute_reply.started":"2024-04-29T14:23:08.605177Z","shell.execute_reply":"2024-04-29T14:23:08.616369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.A Removing rows with missing values","metadata":{"id":"v96VUyPYScSL","_uuid":"10bb2143731149217bd59b8ea7fb2f12706dd355"}},{"cell_type":"code","source":"# Dropped the 8 rows with missing values in the column, SES\ndf_dropna = df.dropna(axis=0, how='any')\npd.isnull(df_dropna).sum()","metadata":{"id":"NCuXVrJtScSM","outputId":"29e022db-bb16-44f6-bfc7-3cd3fbb6f930","_uuid":"71f15a1cda750ae72a718d2ec0aa7939ac2b7855","execution":{"iopub.status.busy":"2024-04-29T14:23:08.619703Z","iopub.execute_input":"2024-04-29T14:23:08.620188Z","iopub.status.idle":"2024-04-29T14:23:08.638958Z","shell.execute_reply.started":"2024-04-29T14:23:08.620114Z","shell.execute_reply":"2024-04-29T14:23:08.636550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_dropna['Group'].value_counts()","metadata":{"id":"ThXMkCk0ScSQ","outputId":"24c17bc4-f411-470d-e483-cd6098eff679","_uuid":"a08f0ff032efa883e45e9b5bd2b6d386dd89f9b3","execution":{"iopub.status.busy":"2024-04-29T14:23:08.641951Z","iopub.execute_input":"2024-04-29T14:23:08.642373Z","iopub.status.idle":"2024-04-29T14:23:08.658672Z","shell.execute_reply.started":"2024-04-29T14:23:08.642294Z","shell.execute_reply":"2024-04-29T14:23:08.657352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.B Imputation\n\nScikit-learn provides package for imputation [6], but we do it manually. Since the *SES* is a discrete variable, we use median for the imputation.","metadata":{"id":"A0ipe9qsScSU","_uuid":"9a81499adca6b212e798a6b9a123c5806d57e087"}},{"cell_type":"code","source":"# Draw scatter plot between EDUC and SES\nx = df['EDUC']\ny = df['SES']\n\nses_not_null_index = y[~y.isnull()].index\nx = x[ses_not_null_index]\ny = y[ses_not_null_index]\n\n# Draw trend line in red\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x, y, 'go', x, p(x), \"r--\")\nplt.xlabel('Education Level(EDUC)')\nplt.ylabel('Social Economic Status(SES)')\n\nplt.show()","metadata":{"id":"62IgZtwnScSV","outputId":"a5e8f86e-66d6-4147-83f7-f26b12787245","_uuid":"1c2354281b56aaac81b5dd09cee531be85a72b1f","execution":{"iopub.status.busy":"2024-04-29T14:23:08.660990Z","iopub.execute_input":"2024-04-29T14:23:08.661669Z","iopub.status.idle":"2024-04-29T14:23:08.839045Z","shell.execute_reply.started":"2024-04-29T14:23:08.661520Z","shell.execute_reply":"2024-04-29T14:23:08.838316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby(['EDUC'])['SES'].median()","metadata":{"id":"cKaMRSvgScSY","outputId":"f05f5530-b14c-4bb8-abbb-037e2a0838e3","_uuid":"d2fcc229a25ba9ad1097de001cd53505ad0ba478","execution":{"iopub.status.busy":"2024-04-29T14:23:08.840451Z","iopub.execute_input":"2024-04-29T14:23:08.840899Z","iopub.status.idle":"2024-04-29T14:23:08.850964Z","shell.execute_reply.started":"2024-04-29T14:23:08.840853Z","shell.execute_reply":"2024-04-29T14:23:08.850076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"SES\"].fillna(df.groupby(\"EDUC\")[\"SES\"].transform(\"median\"), inplace=True)","metadata":{"id":"dj_edAcdScSb","_uuid":"b41fdf3fc1f569f482e8a506f0737775e84b338a","execution":{"iopub.status.busy":"2024-04-29T14:23:08.852404Z","iopub.execute_input":"2024-04-29T14:23:08.852800Z","iopub.status.idle":"2024-04-29T14:23:08.868321Z","shell.execute_reply.started":"2024-04-29T14:23:08.852732Z","shell.execute_reply":"2024-04-29T14:23:08.866825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I confirm there're no more missing values and all the 150 data were used.\npd.isnull(df['SES']).value_counts()","metadata":{"id":"Y4SgUM58ScSd","outputId":"9325d3dc-7f01-4be2-a932-a39c68d202b7","_uuid":"63c36b7bc32f5cc65c8bf908113ba919a17fc5b8","execution":{"iopub.status.busy":"2024-04-29T14:23:08.869991Z","iopub.execute_input":"2024-04-29T14:23:08.870369Z","iopub.status.idle":"2024-04-29T14:23:08.887213Z","shell.execute_reply.started":"2024-04-29T14:23:08.870310Z","shell.execute_reply":"2024-04-29T14:23:08.886277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.C Splitting Train/Validation/Test Sets","metadata":{"_uuid":"61220f51b25e5efcc5ceaa0d8f133967514b33a5"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler \nfrom sklearn.model_selection import cross_val_score","metadata":{"id":"kJcRjpOIScSj","_uuid":"b039c111537091add5e04716b4d33501855155e8","execution":{"iopub.status.busy":"2024-04-29T14:23:08.888615Z","iopub.execute_input":"2024-04-29T14:23:08.889112Z","iopub.status.idle":"2024-04-29T14:23:08.900957Z","shell.execute_reply.started":"2024-04-29T14:23:08.889059Z","shell.execute_reply":"2024-04-29T14:23:08.899305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset with imputation\nY = df['Group'].values # Target for the model\nX = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n\n# splitting into three sets\nX_trainval, X_test, Y_trainval, Y_test = train_test_split(\n    X, Y, random_state=0)\n\n# Feature scaling\nscaler = MinMaxScaler().fit(X_trainval)\nX_trainval_scaled = scaler.transform(X_trainval)\nX_test_scaled = scaler.transform(X_test)","metadata":{"id":"eI6EXWT7ScSm","_uuid":"9c0cd7fedabdd26e4dbd2e5ed19a79c9097511c8","execution":{"iopub.status.busy":"2024-04-29T14:23:08.902454Z","iopub.execute_input":"2024-04-29T14:23:08.902946Z","iopub.status.idle":"2024-04-29T14:23:08.921519Z","shell.execute_reply.started":"2024-04-29T14:23:08.902862Z","shell.execute_reply":"2024-04-29T14:23:08.920086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset after dropping missing value rows\nY = df_dropna['Group'].values # Target for the model\nX = df_dropna[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n\n# splitting into three sets\nX_trainval_dna, X_test_dna, Y_trainval_dna, Y_test_dna = train_test_split(\n    X, Y, random_state=0)\n\n# Feature scaling\nscaler = MinMaxScaler().fit(X_trainval_dna)\nX_trainval_scaled_dna = scaler.transform(X_trainval_dna)\nX_test_scaled_dna = scaler.transform(X_test_dna)","metadata":{"id":"oQAwHijeScSq","_uuid":"aa47c091672863c3ad5c785a65cf227977cb9c37","execution":{"iopub.status.busy":"2024-04-29T14:23:08.923569Z","iopub.execute_input":"2024-04-29T14:23:08.924034Z","iopub.status.idle":"2024-04-29T14:23:08.943417Z","shell.execute_reply.started":"2024-04-29T14:23:08.923946Z","shell.execute_reply":"2024-04-29T14:23:08.942397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.D Cross-validation\nWe conduct 5-fold cross-validation to figure out the best parameters for each model, Logistic Regression, SVM, Decision Tree, Random Forests, and AdaBoost. Since our performance metric is accuracy, we find the best tuning parameters by *accuracy*. In the end, we compare the accuracy, recall and AUC for each model.","metadata":{"id":"Hh0VrtWIScSt","_uuid":"b2356d2f3b9b746909c52e98c88c9dd9e20f77bf"}},{"cell_type":"markdown","source":"# 6. MODEL\n---","metadata":{"id":"vgYxX0OkScSj","_uuid":"27d4266a859c95510a8355df6c98c741a4805224"}},{"cell_type":"markdown","source":"## 6.A Performance Measures\n\nWe use area under the receiver operating characteristic curve (AUC) as our main performance measure. We believe that in case of medical diagnostics for non-life threatening terminal diseases like most neurodegenerative diseases it is important to have a high true positive rate so that all patients with alzheimer's are identified as early as possible. But we also want to make sure that the false positive rate is as low as possible since we do not want to misdiagnose a healthy adult as demented and begin medical therapy. Hence AUC seemed like a ideal choice for a performance measure.\n\nWe will also be looking at accuracy and recall for each model.\n\nIn the figure below, you can think relevant elements as actually demented subjects.\nPrecision and Recall [12]\n![Precision and Recall](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)","metadata":{"id":"ZmzXtTaFScSs","_uuid":"3bef5c29ca278b2aee2e6d0786e78149ab1bd83d"}},{"cell_type":"markdown","source":"## 6.B Logistic Regression\nThe parameter C, inverse of regularization strength.\n\nTuning range: [0.001, 0.1, 1, 10, 100]","metadata":{"id":"L0zOT1CAScSu","_uuid":"52d9efbf3184f96ff3a0767e08d3d1e6f8ea1a73"}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc","metadata":{"_uuid":"f8dcc6798d6f0aa777fff85c880a47ec78ad9e5c","execution":{"iopub.status.busy":"2024-04-29T14:23:08.944734Z","iopub.execute_input":"2024-04-29T14:23:08.945241Z","iopub.status.idle":"2024-04-29T14:23:08.964194Z","shell.execute_reply.started":"2024-04-29T14:23:08.945186Z","shell.execute_reply":"2024-04-29T14:23:08.962775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = [] # list to store all performance metric","metadata":{"id":"nvBhRVT_ScSu","_uuid":"252a6294c3c8754c0e19660e5ad7c0af189fd8e5","execution":{"iopub.status.busy":"2024-04-29T14:23:08.966736Z","iopub.execute_input":"2024-04-29T14:23:08.967195Z","iopub.status.idle":"2024-04-29T14:23:08.979316Z","shell.execute_reply.started":"2024-04-29T14:23:08.967122Z","shell.execute_reply":"2024-04-29T14:23:08.977510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset with imputation\nbest_score=0\nkfolds=5 # set the number of folds\n\nfor c in [0.001, 0.1, 1, 10, 100]:\n    logRegModel = LogisticRegression(C=c)\n    # perform cross-validation\n    scores = cross_val_score(logRegModel, X_trainval, Y_trainval, cv=kfolds, scoring='accuracy') # Get recall for each parameter setting\n    \n    # compute mean cross-validation accuracy\n    score = np.mean(scores)\n    \n    # Find the best parameters and score\n    if score > best_score:\n        best_score = score\n        best_parameters = c\n\n# rebuild a model on the combined training and validation set\nSelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled, Y_trainval)\n\ntest_score = SelectedLogRegModel.score(X_test_scaled, Y_test)\nPredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameter for regularization (C) is: \", best_parameters)\nprint(\"Test accuracy with best C parameter is\", test_score)\nprint(\"Test recall with the best C parameter is\", test_recall)\nprint(\"Test AUC with the best C parameter is\", test_auc)\nm = 'Logistic Regression (w/ imputation)'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"id":"xsWC0JpIScSw","outputId":"f0c4357e-951e-4078-9356-f01f7326c056","_uuid":"cb9f7249fa6793ec6e339aeb9936c26fbdfe552d","execution":{"iopub.status.busy":"2024-04-29T14:23:08.981460Z","iopub.execute_input":"2024-04-29T14:23:08.982038Z","iopub.status.idle":"2024-04-29T14:23:09.147483Z","shell.execute_reply.started":"2024-04-29T14:23:08.981963Z","shell.execute_reply":"2024-04-29T14:23:09.146188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset after dropping missing value rows\nbest_score=0\nkfolds=5 # set the number of folds\n\nfor c in [0.001, 0.1, 1, 10, 100]:\n    logRegModel = LogisticRegression(C=c)\n    # perform cross-validation\n    scores = cross_val_score(logRegModel, X_trainval_scaled_dna, Y_trainval_dna, cv=kfolds, scoring='accuracy')\n    \n    # compute mean cross-validation accuracy\n    score = np.mean(scores)\n    \n    # Find the best parameters and score\n    if score > best_score:\n        best_score = score\n        best_parameters = c\n\n# rebuild a model on the combined training and validation set\nSelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled_dna, Y_trainval_dna)\n\ntest_score = SelectedLogRegModel.score(X_test_scaled_dna, Y_test_dna)\nPredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameter for regularization (C) is: \", best_parameters)\nprint(\"Test accuracy with best C parameter is\", test_score)        \nprint(\"Test recall with the best C parameter is\", test_recall)\nprint(\"Test AUC with the best C parameter is\", test_auc)\n\nm = 'Logistic Regression (w/ dropna)'\nacc.append([m, test_score, test_recall, test_recall, fpr, tpr, thresholds])","metadata":{"id":"Zb-VqkXUScSz","outputId":"2f1858c0-335a-4720-dc18-bef6e3c10a9e","_uuid":"200d475f03c493ecc5de448537841771d0817eb9","execution":{"iopub.status.busy":"2024-04-29T14:23:09.149409Z","iopub.execute_input":"2024-04-29T14:23:09.150118Z","iopub.status.idle":"2024-04-29T14:23:09.273668Z","shell.execute_reply.started":"2024-04-29T14:23:09.150041Z","shell.execute_reply":"2024-04-29T14:23:09.272446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In overall, dataset with imputation outperforms the one without imputation. For the later models, we use dataset without imputation.","metadata":{"_uuid":"9b30f505fa1febaa9b0577ef2943906046f77413"}},{"cell_type":"markdown","source":"## 6.C SVM\nC: Penalty parameter C of the error term. [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n\ngamma: kernel coefficient. [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n\nkernel: kernel type. ['rbf', 'linear', 'poly', 'sigmoid']","metadata":{"id":"Gj3b-ssXScS2","_uuid":"c3fcf0473df26fdea9ba51953aab1f53b2e522c5"}},{"cell_type":"code","source":"best_score = 0\n\nfor c_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter C\n    for gamma_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter gamma\n        for k_parameter in ['rbf', 'linear', 'poly', 'sigmoid']: # iterate over the values we need to try for the kernel parameter\n            svmModel = SVC(kernel=k_parameter, C=c_paramter, gamma=gamma_paramter) #define the model\n            # perform cross-validation\n            scores = cross_val_score(svmModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n            # the training set will be split internally into training and cross validation\n\n            # compute mean cross-validation accuracy\n            score = np.mean(scores)\n            # if we got a better score, store the score and parameters\n            if score > best_score:\n                best_score = score #store the score \n                best_parameter_c = c_paramter #store the parameter c\n                best_parameter_gamma = gamma_paramter #store the parameter gamma\n                best_parameter_k = k_parameter\n            \n\n# rebuild a model with best parameters to get score \nSelectedSVMmodel = SVC(C=best_parameter_c, gamma=best_parameter_gamma, kernel=best_parameter_k).fit(X_trainval_scaled, Y_trainval)\n\ntest_score = SelectedSVMmodel.score(X_test_scaled, Y_test)\nPredictedOutput = SelectedSVMmodel.predict(X_test_scaled)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on cross validation set is:\", best_score)\nprint(\"Best parameter for c is: \", best_parameter_c)\nprint(\"Best parameter for gamma is: \", best_parameter_gamma)\nprint(\"Best parameter for kernel is: \", best_parameter_k)\nprint(\"Test accuracy with the best parameters is\", test_score)\nprint(\"Test recall with the best parameters is\", test_recall)\nprint(\"Test recall with the best parameter is\", test_auc)\n\nm = 'SVM'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"id":"Xp5EM__NScS2","outputId":"ac91ced2-9648-4248-8c62-6babfb401178","_uuid":"527bf4c3aaeb65eeb16f929c2c8c82ce4c2263c2","execution":{"iopub.status.busy":"2024-04-29T14:23:09.275639Z","iopub.execute_input":"2024-04-29T14:23:09.276036Z","iopub.status.idle":"2024-04-29T14:23:16.478525Z","shell.execute_reply.started":"2024-04-29T14:23:09.275971Z","shell.execute_reply":"2024-04-29T14:23:16.477069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.D Decision Tree\nMaximum depth. [1, 2, ..., 8]\n\n8 is the number of features","metadata":{"id":"mYGAer5hScS5","_uuid":"2a111665a3aeefa0449d6e9b86efb45e14e5996d"}},{"cell_type":"code","source":"best_score = 0\n\nfor md in range(1, 9): # iterate different maximum depth values\n    # train the model\n    treeModel = DecisionTreeClassifier(random_state=0, max_depth=md, criterion='gini')\n    # perform cross-validation\n    scores = cross_val_score(treeModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n    \n    # compute mean cross-validation accuracy\n    score = np.mean(scores)\n    \n    # if we got a better score, store the score and parameters\n    if score > best_score:\n        best_score = score\n        best_parameter = md\n\n# Rebuild a model on the combined training and validation set        \nSelectedDTModel = DecisionTreeClassifier(max_depth=best_parameter).fit(X_trainval_scaled, Y_trainval )\n\ntest_score = SelectedDTModel.score(X_test_scaled, Y_test)\nPredictedOutput = SelectedDTModel.predict(X_test_scaled)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameter for the maximum depth is: \", best_parameter)\nprint(\"Test accuracy with best parameter is \", test_score)\nprint(\"Test recall with best parameters is \", test_recall)\nprint(\"Test AUC with the best parameter is \", test_auc)\n\nm = 'Decision Tree'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"id":"jGI1Smg7ScS6","outputId":"86ea4ca6-b57f-47c0-fc4c-a958e1da8f95","_uuid":"4c27de17e77f9b986e27d2090113bce38bd67fba","execution":{"iopub.status.busy":"2024-04-29T14:23:16.480483Z","iopub.execute_input":"2024-04-29T14:23:16.480903Z","iopub.status.idle":"2024-04-29T14:23:16.616323Z","shell.execute_reply.started":"2024-04-29T14:23:16.480820Z","shell.execute_reply":"2024-04-29T14:23:16.615073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Feature importance: \")\nnp.array([X.columns.values.tolist(), list(SelectedDTModel.feature_importances_)]).T","metadata":{"id":"3k1LzTAOScS9","outputId":"c4d23b31-7cde-459d-c745-df64c9716cad","_uuid":"802da5f22fbe73ff4d4ff097408da95100fababe","execution":{"iopub.status.busy":"2024-04-29T14:23:16.618046Z","iopub.execute_input":"2024-04-29T14:23:16.618348Z","iopub.status.idle":"2024-04-29T14:23:16.628444Z","shell.execute_reply.started":"2024-04-29T14:23:16.618296Z","shell.execute_reply":"2024-04-29T14:23:16.627046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import export_graphviz\nimport graphviz \ndot_data=export_graphviz(SelectedDTModel, feature_names=X_trainval.columns.values.tolist(),out_file=None)\ngraph = graphviz.Source(dot_data)  \ngraph ","metadata":{"id":"jAXEhs2gScS_","outputId":"8fccfeea-ec7f-4bad-9029-0b66b4aa09f7","_uuid":"9df711a59c1470af47f2c5a83f2e9cb11dcb00c7","execution":{"iopub.status.busy":"2024-04-29T14:23:16.630634Z","iopub.execute_input":"2024-04-29T14:23:16.631144Z","iopub.status.idle":"2024-04-29T14:23:16.692281Z","shell.execute_reply.started":"2024-04-29T14:23:16.631053Z","shell.execute_reply":"2024-04-29T14:23:16.690965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.E Random Forest Classifier\nn_estimators(M): the number of trees in the forest\n\nmax_features(d): the number of features to consider when looking for the best split\n\nmax_depth(m): the maximum depth of the tree. ","metadata":{"id":"ZkIF7600ScTD","_uuid":"20608c740de79f3ea76598be6c3e3e8fd158fd82"}},{"cell_type":"code","source":"best_score = 0\n\nfor M in range(2, 15, 2): # combines M trees\n    for d in range(1, 9): # maximum number of features considered at each split\n        for m in range(1, 9): # maximum depth of the tree\n            # train the model\n            # n_jobs(4) is the number of parallel computing\n            forestModel = RandomForestClassifier(n_estimators=M, max_features=d, n_jobs=4,\n                                          max_depth=m, random_state=0)\n        \n            # perform cross-validation\n            scores = cross_val_score(forestModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n\n            # compute mean cross-validation accuracy\n            score = np.mean(scores)\n\n            # if we got a better score, store the score and parameters\n            if score > best_score:\n                best_score = score\n                best_M = M\n                best_d = d\n                best_m = m\n\n# Rebuild a model on the combined training and validation set        \nSelectedRFModel = RandomForestClassifier(n_estimators=M, max_features=d,\n                                          max_depth=m, random_state=0).fit(X_trainval_scaled, Y_trainval )\n\nPredictedOutput = SelectedRFModel.predict(X_test_scaled)\ntest_score = SelectedRFModel.score(X_test_scaled, Y_test)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameters of M, d, m are: \", best_M, best_d, best_m)\nprint(\"Test accuracy with the best parameters is\", test_score)\nprint(\"Test recall with the best parameters is:\", test_recall)\nprint(\"Test AUC with the best parameters is:\", test_auc)\n\nm = 'Random Forest'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"id":"zi0Ssns3ScTE","outputId":"e7adb6b8-ccfd-47b4-f65c-01848c1a0450","_uuid":"0314f070def4da297b2b8712cea7727f6d5d8112","execution":{"iopub.status.busy":"2024-04-29T14:23:16.694938Z","iopub.execute_input":"2024-04-29T14:23:16.695447Z","iopub.status.idle":"2024-04-29T14:31:26.017136Z","shell.execute_reply.started":"2024-04-29T14:23:16.695366Z","shell.execute_reply":"2024-04-29T14:31:26.015964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Feature importance: \")\nnp.array([X.columns.values.tolist(), list(SelectedRFModel.feature_importances_)]).T","metadata":{"id":"Mcx6LmzcScTJ","outputId":"f7ba2e6f-1a5b-4495-a9b1-2a0973101259","_uuid":"7264a60baa490343e92e743d43f635a18af9fa13","execution":{"iopub.status.busy":"2024-04-29T14:31:26.019036Z","iopub.execute_input":"2024-04-29T14:31:26.019407Z","iopub.status.idle":"2024-04-29T14:31:26.032611Z","shell.execute_reply.started":"2024-04-29T14:31:26.019350Z","shell.execute_reply":"2024-04-29T14:31:26.031493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.F AdaBoost","metadata":{"_uuid":"ea3b9dd38fd2bbfe32e1cdd35ed6a3cdfa2dbccc"}},{"cell_type":"code","source":"best_score = 0\n\nfor M in range(2, 15, 2): # combines M trees\n    for lr in [0.0001, 0.001, 0.01, 0.1, 1]:\n        # train the model\n        boostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0)\n\n        # perform cross-validation\n        scores = cross_val_score(boostModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n\n        # compute mean cross-validation accuracy\n        score = np.mean(scores)\n\n        # if we got a better score, store the score and parameters\n        if score > best_score:\n            best_score = score\n            best_M = M\n            best_lr = lr\n\n# Rebuild a model on the combined training and validation set        \nSelectedBoostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0).fit(X_trainval_scaled, Y_trainval )\n\nPredictedOutput = SelectedBoostModel.predict(X_test_scaled)\ntest_score = SelectedRFModel.score(X_test_scaled, Y_test)\ntest_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\nfpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\ntest_auc = auc(fpr, tpr)\nprint(\"Best accuracy on validation set is:\", best_score)\nprint(\"Best parameter of M is: \", best_M)\nprint(\"best parameter of LR is: \", best_lr)\nprint(\"Test accuracy with the best parameter is\", test_score)\nprint(\"Test recall with the best parameters is:\", test_recall)\nprint(\"Test AUC with the best parameters is:\", test_auc)\n\nm = 'AdaBoost'\nacc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])","metadata":{"_uuid":"9eab03ab2cd59e507dc30b632c60fb0aeb1d2c37","execution":{"iopub.status.busy":"2024-04-29T14:31:26.034511Z","iopub.execute_input":"2024-04-29T14:31:26.035025Z","iopub.status.idle":"2024-04-29T14:31:28.786755Z","shell.execute_reply.started":"2024-04-29T14:31:26.034939Z","shell.execute_reply":"2024-04-29T14:31:28.785517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Feature importance: \")\nnp.array([X.columns.values.tolist(), list(SelectedBoostModel.feature_importances_)]).T","metadata":{"_uuid":"a240cd4c2abd5b9bb46c10b21d157e663665a2bb","execution":{"iopub.status.busy":"2024-04-29T14:31:28.788558Z","iopub.execute_input":"2024-04-29T14:31:28.788959Z","iopub.status.idle":"2024-04-29T14:31:28.799770Z","shell.execute_reply.started":"2024-04-29T14:31:28.788823Z","shell.execute_reply":"2024-04-29T14:31:28.798734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. CONCLUSION\n\n## 7.A RESULTS","metadata":{"id":"w1vFrwcwScTO","_uuid":"5defe4c299e6a47547b1d05a533c90aba26c0365"}},{"cell_type":"code","source":"# Performance Metric for each model\nresult = pd.DataFrame(acc, columns=['Model', 'Accuracy', 'Recall', 'AUC', 'FPR', 'TPR', 'TH'])\nresult[['Model', 'Accuracy', 'Recall', 'AUC']]","metadata":{"_uuid":"567d27a76de89fd5c9feb715bfc0e58400872f7e","execution":{"iopub.status.busy":"2024-04-29T14:31:28.801643Z","iopub.execute_input":"2024-04-29T14:31:28.801977Z","iopub.status.idle":"2024-04-29T14:31:28.825486Z","shell.execute_reply.started":"2024-04-29T14:31:28.801897Z","shell.execute_reply":"2024-04-29T14:31:28.824339Z"},"trusted":true},"execution_count":null,"outputs":[]}]}